{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\yamuna\\anaconda3\\lib\\site-packages (2.4.3)\n",
      "Requirement already satisfied: h5py in c:\\users\\yamuna\\anaconda3\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\yamuna\\anaconda3\\lib\\site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\yamuna\\anaconda3\\lib\\site-packages (from keras) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\yamuna\\anaconda3\\lib\\site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: six in c:\\users\\yamuna\\anaconda3\\lib\\site-packages (from h5py->keras) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imghdr\n",
    "import optparse\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import rotate\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import collections\n",
    "from scipy.signal import argrelextrema\n",
    "from PIL import Image\n",
    "# Keras with tensorflow backend\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "import json\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "import json\n",
    "import socket\n",
    "import struct\n",
    "import charSegmentation\n",
    "import utils\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "############################################################################################################################## \n",
    "# Model and some files loading part\n",
    "############################################################################################################################## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model File!!!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-1ddfc376d7cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0mout_image_4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout_image_3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcnts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_image_4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETR_TREE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHAIN_APPROX_SIMPLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[0mout_image_6\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "def file_char_vattu_gunintam(file_name):\n",
    "    file_1 = open(file_name,'r')\n",
    "    part_1_1 = []\n",
    "    part_1_2 = []\n",
    "\n",
    "    part_1_1.append(file_1.readline())\n",
    "    k = file_1.readline()\n",
    "    while k != '' :\n",
    "        part_1_2.append(k)\n",
    "        part_1_1.append(file_1.readline())\n",
    "        k = file_1.readline()\n",
    "\n",
    "    if part_1_2[len(part_1_2)-1]=='':\n",
    "        del part_1_2[-1]\n",
    "\n",
    "    if part_1_1[len(part_1_1)-1]=='':\n",
    "        del part_1_1[-1]\n",
    "\n",
    "    for i in range(len(part_1_1)):\n",
    "        part_1_1[i] = int(part_1_1[i])\n",
    "    return (part_1_1,part_1_2)\n",
    "\n",
    "# Model for only characters\n",
    "with open('../models/main_character/ours/model_chars_tccnn-l.json') as infile:\n",
    "    json_char = json.load(infile)\n",
    "\n",
    "model_1 = model_from_json(json_char)\n",
    "model_1.load_weights('../models/main_character/ours/model_chars_tccnn-l.hdf5')\n",
    "\n",
    "# Model for vattulu and gunintalu\n",
    "with open('../models/vattu_gunintam/ours/model_v_g.json') as infile:\n",
    "    json_char = json.load(infile)\n",
    "\n",
    "model_2 = model_from_json(json_char)\n",
    "model_2.load_weights('../models/vattu_gunintam/ours/model_v_g_weights.hdf5')\n",
    "\n",
    "(char_1,char_2) = file_char_vattu_gunintam('char.txt')\n",
    "\n",
    "(vattu_1,vattu_2) = file_char_vattu_gunintam('vattu_gunintam.txt')\n",
    "\n",
    "print('Loaded Model File!!!')\n",
    "\n",
    "while(1):\n",
    "    \n",
    "############################################################################################################################## \n",
    "# Image Processing and recognition part\n",
    "############################################################################################################################## \n",
    "\n",
    "    file_name = 'img.jpg'\n",
    "    img = np.asarray(cv2.imread(file_name,0))\n",
    "    kernel = np.ones((9,9),np.uint8)\n",
    "    erode = cv2.erode(img,kernel,iterations = 1)\n",
    "    angle = utils.deskew(erode)\n",
    "    rows,cols = img.shape\n",
    "    img = cv2.imread(file_name,0)\n",
    "    rows,cols = img.shape\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),int(angle),1)\n",
    "    gray_scale = cv2.warpAffine(img,M,(cols,rows))\n",
    "\n",
    "    # mser properties\n",
    "    _delta=5\n",
    "    _min_area=60\n",
    "    _max_area=14400\n",
    "    _max_variation=0.25\n",
    "    _min_diversity=.2\n",
    "    _max_evolution=200\n",
    "    _area_threshold=1.01\n",
    "    _min_margin=0.003\n",
    "    _edge_blur_size=5\n",
    "\n",
    "    mser = cv2.MSER_create(_delta,_min_area,_max_area,_max_variation,_min_diversity,_max_evolution,_area_threshold,_min_margin,_edge_blur_size)\n",
    "\n",
    "    regions = mser.detectRegions(gray_scale)\n",
    "\n",
    "    out_image_2 = np.zeros(gray_scale.shape,dtype='uint8')\n",
    "\n",
    "    bool_idx = []\n",
    "    regions_2 = []\n",
    "    areas_regions = []\n",
    "    for i in range(len(regions)):\n",
    "        kk = np.asarray(regions[i])\n",
    "        min_1 = np.amin(kk[:][0])\n",
    "        max_1 = np.amax(kk[:][0])\n",
    "        min_2 = np.amin(kk[:][1])\n",
    "        max_2 = np.amax(kk[:][1])\n",
    "        ratio = float(len(regions[i]))/((max_2-min_2)*(max_1-min_1))       \n",
    "        if max_2==min_2 or max_1==min_1:\n",
    "            bool_idx.append(False)\n",
    "        else:\n",
    "            if (not(float(max_2-min_2)/float(max_1-min_1) < 0.1 or float(max_1-min_1)/float(max_2-min_2) <0.1 or ratio<0.2)):\n",
    "                out_image_2[ kk[:,1] , kk[:,0] ] = 255\n",
    "                areas_regions.append((max_2-min_2)*(max_1-min_1))\n",
    "                regions_2.append(regions[i])\n",
    "                bool_idx.append(True)\n",
    "            else :\n",
    "                bool_idx.append(False)\n",
    "\n",
    "    areas_regions = np.asarray(areas_regions)\n",
    "\n",
    "    regions = regions_2\n",
    "\n",
    "    n,bins,patches=plt.hist(areas_regions,bins=\"auto\")\n",
    "\n",
    "    average = 0\n",
    "    num = 0\n",
    "    for i in range(len(areas_regions)):\n",
    "        if areas_regions[i]>bins[np.argmax(n)] and areas_regions[i]<bins[np.argmax(n)+1]:\n",
    "            average = average + areas_regions[i]\n",
    "            num = num + 1\n",
    "    if num>0:        \n",
    "        average = average/float(num)\n",
    "\n",
    "\n",
    "    kernell = np.ones((1,int(0.7*np.sqrt(average))),np.uint8)\n",
    "    appx_size = int(0.7*np.sqrt(average))\n",
    "    out_image_3 = cv2.dilate(out_image_2,kernell,iterations=1)\n",
    "    kernell = np.ones((int(0.2*np.sqrt(average)),1),np.uint8)\n",
    "    out_image_3 = cv2.dilate(out_image_3,kernell,iterations=1)\n",
    "\n",
    "    out_image_4 = out_image_3[:,:]\n",
    "    (_,cnts, _) = cv2.findContours(out_image_4.astype(np.uint8).copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    out_image_6 = deepcopy(np.asarray(gray_scale))\n",
    "    regions1 = []\n",
    "\n",
    "    for i in range(len(cnts)):\n",
    "        x,y,w,h = cv2.boundingRect(cnts[i])\n",
    "        \n",
    "        include = True\n",
    "        \n",
    "        for j in range(len(cnts)):\n",
    "            if j!= i:\n",
    "                x1,y1,w1,h1 = cv2.boundingRect(cnts[j])\n",
    "                if x>=x1 and y>=y1 and x+w<=x1+w1 and y+h<=y1+h1:\n",
    "                    include = False\n",
    "\n",
    "        if (h>2*appx_size or w>2*appx_size or w*h>100) and include:\n",
    "            cv2.rectangle(out_image_6,(x,y),(x+w,y+h),(255),3)\n",
    "            regions1.append([x,y,w,h])\n",
    "            \n",
    "    cv2.imwrite('output/region_seg.png',out_image_6)\n",
    "    regions1 = np.array(regions1)\n",
    "    regions1 = regions1[np.argsort(regions1[:, 1])]\n",
    "\n",
    "    regions2 = [[] for i in range(len(regions1))]\n",
    "    regions2[0].append(regions1[0])\n",
    "    line_idx = 0\n",
    "\n",
    "    for i in range(1,len(regions1)):\n",
    "        x,y,w,h = regions1[i]\n",
    "        xa,ya,wa,ha = regions1[i-1]\n",
    "        a = max(y,ya)\n",
    "        b = min(h+y,ha+ya)\n",
    "        if(b-a)>0:\n",
    "            regions2[line_idx].append(regions1[i])\n",
    "        else:\n",
    "            line_idx = line_idx + 1\n",
    "            regions2[line_idx].append(regions1[i]) \n",
    "    regions2 = np.array(regions2)\n",
    "    regions2 = [x for x in regions2 if x != []]\n",
    "\n",
    "    for i in range(len(regions2)):\n",
    "        newline = np.array(regions2[i])\n",
    "        newline = newline[np.argsort(newline[:, 0])]\n",
    "        regions2[i] = newline\n",
    "    new_regions = []    \n",
    "    for i in range( len(regions2)):\n",
    "        for j in range(len(regions2[i])):\n",
    "            new_regions.append(regions2[i][j])\n",
    "\n",
    "    positions = []\n",
    "    Text_regions = []\n",
    "    k = []\n",
    "\n",
    "    line_idx = np.zeros((len(new_regions),len(new_regions)))\n",
    "    p = np.asarray(new_regions)\n",
    "\n",
    "    new_regions_3 = np.zeros(p.shape)\n",
    "    aa = np.argsort(p[:, 1])\n",
    "    for i in range(len(new_regions_3)):\n",
    "        new_regions_3[i] = new_regions[aa[i]]\n",
    "\n",
    "    for i in range(len(new_regions_3)):\n",
    "        for j in range(len(new_regions_3)):\n",
    "            max_1 = max( new_regions_3[i][1] , new_regions_3[j][1] )\n",
    "            min_1 = min( new_regions_3[i][3] + new_regions_3[i][1] , new_regions_3[j][3] + new_regions_3[j][1] )\n",
    "            if min_1-max_1 > ((new_regions_3[i][3]) + (new_regions_3[j][3]))/4.0:\n",
    "                line_idx[i,j] = 1\n",
    "\n",
    "    new_regions_update = []    \n",
    "\n",
    "    indexer = np.zeros(len(new_regions_3))\n",
    "    for i in range(len(new_regions_3)):\n",
    "        count = 0\n",
    "        for j in range(len(new_regions_3)):\n",
    "            if line_idx[j,i]==1:\n",
    "                indexer[i] = indexer[i] + new_regions_3[j][1]\n",
    "                count = count + 1\n",
    "        indexer[i] = indexer[i]/float(count)\n",
    "\n",
    "    kko =  []\n",
    "    kko.append(0)\n",
    "    count = 0\n",
    "    checker = np.zeros(len(new_regions_3))\n",
    "    for i in range(len(new_regions_3)):\n",
    "        for j in range(len(new_regions_3)):\n",
    "            if checker[j]==0 and line_idx[i,j]==1:\n",
    "                new_regions_update.append(new_regions_3[j])\n",
    "                checker[j] = 1\n",
    "                count  = count + 1\n",
    "        kko.append(count)\n",
    "\n",
    "    for i in range(len(kko)-1):\n",
    "        if kko[i+1]-kko[i]!=1 and kko[i+1]-kko[i]!=0:\n",
    "            part = np.asarray(new_regions_update[kko[i]:kko[i+1]])\n",
    "            part = part[np.argsort(part[:, 0])]\n",
    "            new_regions_update[kko[i]:kko[i+1]] = part\n",
    "        elif kko[i+1]-kko[i]==1:\n",
    "            part = np.asarray(new_regions_update[kko[i]:kko[i+1]])\n",
    "            new_regions_update[kko[i]:kko[i+1]] = part\n",
    "\n",
    "    for i in range(len(regions1)):\n",
    "        x,y,w,h = new_regions_update[i]\n",
    "        x = int(x)\n",
    "        y = int(y)\n",
    "        w = int(w)\n",
    "        h = int(h)\n",
    "        (positions1,Text_regions1) = charSegmentation.complete(deepcopy(gray_scale[y:y+h,x:x+w]))\n",
    "        for j in range(len(positions1)):\n",
    "            positions1[j][0] = np.clip(positions1[j][0],0,np.inf) + y\n",
    "            positions1[j][1] = np.clip(positions1[j][1],0,np.inf) + x\n",
    "            positions1[j][2] = np.clip(positions1[j][2],0,np.inf) + y\n",
    "            positions1[j][3] = np.clip(positions1[j][3],0,np.inf) + x\n",
    "            x1,y1,x2,y2 = positions1[j]\n",
    "            positions.append(positions1[j])\n",
    "            Text_regions.append(Text_regions1[j])\n",
    "            if j!=len(positions1)-1:\n",
    "                k.append(0)\n",
    "        \n",
    "        if not (len(positions1)<1):\n",
    "            k.append(1)\n",
    "\n",
    "    positions = (positions)\n",
    "    Text_regions = (Text_regions)\n",
    "\n",
    "    order = sorted(list(range(len(positions))),key=lambda k :positions[k])\n",
    "    line_idx = np.zeros((len(positions),len(positions)))\n",
    "\n",
    "    for i in range(len(positions)):\n",
    "        for j in range(len(positions)):\n",
    "            max_1 = max( positions[i][0] , positions[j][0] )\n",
    "            min_1 = min( positions[i][2] , positions[j][2] )\n",
    "\n",
    "            if min_1-max_1 > ((positions[i][2]-positions[i][0]) + (positions[j][2]-positions[j][0]))/5.0:\n",
    "                line_idx[i,j] = 1\n",
    "\n",
    "\n",
    "    corresponding_cluster = np.zeros(len(positions))\n",
    "\n",
    "    for i in range(len(positions)-1):\n",
    "        if not(line_idx[i,i+1]==1 and line_idx[i+1,i]==1):\n",
    "            corresponding_cluster[i+1] = 1\n",
    "\n",
    "    chars = []\n",
    "    vattu_gunintam = []\n",
    "    output = []\n",
    "\n",
    "    for i in range(len(Text_regions)):\n",
    "        # segmentation of character\n",
    "        img = utils.crop(Text_regions[i])\n",
    "        cv2.imwrite('output/segmentedChars/'+str(i)+'.PNG',img)\n",
    "        img = Image.open('output/segmentedChars/'+str(i)+'.PNG')\n",
    "        img.load()\n",
    "        if img.size!=(32,32):\n",
    "            img = img.resize((32,32),Image.ANTIALIAS)\n",
    "        img = np.asarray(img).reshape(1,1,32,32)\n",
    "        img = img.astype('float32')\n",
    "        img = img/255.0\n",
    "\n",
    "        # Prediction of char\n",
    "        out =  model_1.predict(img)\n",
    "        output = [output,np.where(out==out.max())[1][:]+1]\n",
    "        chars.append(np.where(out==out.max())[1][:]+1)\n",
    "\n",
    "        # Prediction of vattu or gunintam if necessary\n",
    "        if np.where(out==out.max())[1][:]+1>=20 and np.where(out==out.max())[1][:]+1<=55:\n",
    "            out2 = model_2.predict(img)\n",
    "            vattu_gunintam.append(np.where(out2==out2.max())[1][:]+1)\n",
    "        else:\n",
    "            vattu_gunintam.append(-1)\n",
    "\n",
    "    file = open('output/result.html','w')\n",
    "    \n",
    "    # writing output in html format \n",
    "\n",
    "    for i in range(len(chars)):\n",
    "        if i>0:\n",
    "            if corresponding_cluster[i] == 1:\n",
    "                file.write('<br/>')\n",
    "            elif k[i-1]==1 :\n",
    "                file.write('&#32;')\n",
    "        file.write((char_2[int(chars[i])-1][:-1]))\n",
    "        if vattu_gunintam[i]!=-1 and vattu_gunintam[i] !=1:\n",
    "            file.write(vattu_2[int(vattu_gunintam[i])-1][:-1])\n",
    "\n",
    "    file.close()\n",
    "    \n",
    "    # processing of speech\n",
    "    #os.system(\"espeak -m -v te -s 100 -f output/result.html -w output/speech.wav\")\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
