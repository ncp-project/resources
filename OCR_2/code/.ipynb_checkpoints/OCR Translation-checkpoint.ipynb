{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import argrelextrema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras with tensorflow backend\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib.stride_tricks import as_strided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import charSegmentation\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras.backend.tensorflow_backend as tfback\n",
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model and some files loading part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_char_vattu_gunintam(file_name):\n",
    "    file_1 = open(file_name,'r')\n",
    "    part_1_1 = []\n",
    "    part_1_2 = []\n",
    "\n",
    "    part_1_1.append(file_1.readline())\n",
    "    k = file_1.readline()\n",
    "    while k != '' :\n",
    "        part_1_2.append(k)\n",
    "        part_1_1.append(file_1.readline())\n",
    "        k = file_1.readline()\n",
    "\n",
    "    if part_1_2[len(part_1_2)-1]=='':\n",
    "        del part_1_2[-1]\n",
    "\n",
    "    if part_1_1[len(part_1_1)-1]=='':\n",
    "        del part_1_1[-1]\n",
    "\n",
    "    for i in range(len(part_1_1)):\n",
    "        part_1_1[i] = int(part_1_1[i])\n",
    "    return (part_1_1,part_1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model for only characters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/main_character/ours/model_chars_tccnn-l.json') as infile:\n",
    "    json_char = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = model_from_json(json_char)\n",
    "model_1.load_weights('../models/main_character/ours/model_chars_tccnn-l.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model for vattulu and gunintalu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/vattu_gunintam/ours/model_v_g.json') as infile:\n",
    "    json_char = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = model_from_json(json_char)\n",
    "model_2.load_weights('../models/vattu_gunintam/ours/model_v_g_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "(char_1,char_2) = file_char_vattu_gunintam('char.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "(vattu_1,vattu_2) = file_char_vattu_gunintam('vattu_gunintam.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model File!!!\n",
      "4.4.0\n"
     ]
    }
   ],
   "source": [
    "print('Loaded Model File!!!')\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173 1490\n",
      "436\n",
      "----asdsd----\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Default MaxPoolingOp only supports NHWC on device type CPU\n\t [[node sequential/max_pooling2d_1/MaxPool (defined at <ipython-input-58-f80e47feffa9>:240) ]] [Op:__inference_predict_function_451]\n\nFunction call stack:\npredict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-f80e47feffa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# Prediction of char\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmodel_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mchars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    844\u001b[0m               *args, **kwds)\n\u001b[1;32m    845\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Default MaxPoolingOp only supports NHWC on device type CPU\n\t [[node sequential/max_pooling2d_1/MaxPool (defined at <ipython-input-58-f80e47feffa9>:240) ]] [Op:__inference_predict_function_451]\n\nFunction call stack:\npredict_function\n"
     ]
    }
   ],
   "source": [
    "while(1):\n",
    "    \n",
    "############################################################################################################################## \n",
    "# Image Processing and recognition part\n",
    "############################################################################################################################## \n",
    "\n",
    "    file_name = 'img.jpg'\n",
    "    img = np.asarray(cv2.imread(file_name,0))\n",
    "    #need to check\n",
    "    kernel = np.ones((9,9),np.uint8)\n",
    "    erode = cv2.erode(img,kernel,iterations = 1)\n",
    "    angle = utils.deskew(erode)\n",
    "    rows,cols = img.shape\n",
    "    print(rows,cols)\n",
    "    img = cv2.imread(file_name,0)\n",
    "    rows,cols = img.shape\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),int(angle),1)\n",
    "    gray_scale = cv2.warpAffine(img,M,(cols,rows))\n",
    "\n",
    "    # mser properties\n",
    "    _delta=5\n",
    "    _min_area=60\n",
    "    _max_area=14400\n",
    "    _max_variation=0.25\n",
    "    _min_diversity=.2\n",
    "    _max_evolution=200\n",
    "    _area_threshold=1.01\n",
    "    _min_margin=0.003\n",
    "    _edge_blur_size=5\n",
    "\n",
    "    mser = cv2.MSER_create(_delta,_min_area,_max_area,_max_variation,_min_diversity,_max_evolution,_area_threshold,_min_margin,_edge_blur_size)\n",
    "\n",
    "    regions,boxes = mser.detectRegions(gray_scale)\n",
    "    print(len(regions))\n",
    "    out_image_2 = np.zeros(gray_scale.shape,dtype='uint8')\n",
    "\n",
    "    bool_idx = []\n",
    "    regions_2 = []\n",
    "    areas_regions = []\n",
    "    for i in range(len(regions)):\n",
    "        kk = np.asarray(regions[i])\n",
    "        min_1 = np.amin(kk[:,0])\n",
    "        max_1 = np.amax(kk[:,0])\n",
    "        min_2 = np.amin(kk[:,1])\n",
    "        max_2 = np.amax(kk[:,1])\n",
    "        ratio = float(len(regions[i]))/((max_2-min_2)*(max_1-min_1))       \n",
    "        if max_2==min_2 or max_1==min_1:\n",
    "            bool_idx.append(False)\n",
    "        else:\n",
    "            if (not(float(max_2-min_2)/float(max_1-min_1) < 0.1 or float(max_1-min_1)/float(max_2-min_2) <0.1 or ratio<0.2)):\n",
    "                out_image_2[ kk[:,1] , kk[:,0] ] = 255\n",
    "                areas_regions.append((max_2-min_2)*(max_1-min_1))\n",
    "                regions_2.append(regions[i])\n",
    "                bool_idx.append(True)\n",
    "            else :\n",
    "                bool_idx.append(False)\n",
    "\n",
    "    areas_regions = np.asarray(areas_regions)\n",
    "\n",
    "    regions = regions_2\n",
    "\n",
    "    n,bins,patches=plt.hist(areas_regions,bins=\"auto\")\n",
    "\n",
    "    average = 0\n",
    "    num = 0\n",
    "    for i in range(len(areas_regions)):\n",
    "        if areas_regions[i]>bins[np.argmax(n)] and areas_regions[i]<bins[np.argmax(n)+1]:\n",
    "            average = average + areas_regions[i]\n",
    "            num = num + 1\n",
    "    average = average/float(num)\n",
    "\n",
    "\n",
    "    kernell = np.ones((1,int(0.7*np.sqrt(average))),np.uint8)\n",
    "    appx_size = int(0.7*np.sqrt(average))\n",
    "    out_image_3 = cv2.dilate(out_image_2,kernell,iterations=1)\n",
    "    kernell = np.ones((int(0.2*np.sqrt(average)),1),np.uint8)\n",
    "    out_image_3 = cv2.dilate(out_image_3,kernell,iterations=1)\n",
    "\n",
    "    out_image_4 = out_image_3[:,:]\n",
    "    (cnts,_) = cv2.findContours(out_image_4.astype(np.uint8).copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    print(\"----asdsd----\")\n",
    "    out_image_6 = deepcopy(np.asarray(gray_scale))\n",
    "    regions1 = []\n",
    "\n",
    "    for i in range(len(cnts)):\n",
    "        x,y,w,h = cv2.boundingRect(cnts[i])\n",
    "        \n",
    "        include = True\n",
    "        \n",
    "        for j in range(len(cnts)):\n",
    "            if j!= i:\n",
    "                x1,y1,w1,h1 = cv2.boundingRect(cnts[j])\n",
    "                if x>=x1 and y>=y1 and x+w<=x1+w1 and y+h<=y1+h1:\n",
    "                    include = False\n",
    "\n",
    "        if (h>2*appx_size or w>2*appx_size or w*h>100) and include:\n",
    "            cv2.rectangle(out_image_6,(x,y),(x+w,y+h),(255),3)\n",
    "            regions1.append([x,y,w,h])\n",
    "            \n",
    "    cv2.imwrite('output/region_seg.png',out_image_6)\n",
    "    regions1 = np.array(regions1)\n",
    "    regions1 = regions1[np.argsort(regions1[:, 1])]\n",
    "\n",
    "    regions2 = [[] for i in range(len(regions1))]\n",
    "    regions2[0].append(regions1[0])\n",
    "    line_idx = 0\n",
    "\n",
    "    for i in range(1,len(regions1)):\n",
    "        x,y,w,h = regions1[i]\n",
    "        xa,ya,wa,ha = regions1[i-1]\n",
    "        a = max(y,ya)\n",
    "        b = min(h+y,ha+ya)\n",
    "        if(b-a)>0:\n",
    "            regions2[line_idx].append(regions1[i])\n",
    "        else:\n",
    "            line_idx = line_idx + 1\n",
    "            regions2[line_idx].append(regions1[i]) \n",
    "    regions2 = np.array(regions2)\n",
    "    regions2 = [x for x in regions2 if x != []]\n",
    "\n",
    "    for i in range(len(regions2)):\n",
    "        newline = np.array(regions2[i])\n",
    "        newline = newline[np.argsort(newline[:, 0])]\n",
    "        regions2[i] = newline\n",
    "    new_regions = []    \n",
    "    for i in range( len(regions2)):\n",
    "        for j in range(len(regions2[i])):\n",
    "            new_regions.append(regions2[i][j])\n",
    "\n",
    "    positions = []\n",
    "    Text_regions = []\n",
    "    k = []\n",
    "\n",
    "    line_idx = np.zeros((len(new_regions),len(new_regions)))\n",
    "    p = np.asarray(new_regions)\n",
    "\n",
    "    new_regions_3 = np.zeros(p.shape)\n",
    "    aa = np.argsort(p[:, 1])\n",
    "    for i in range(len(new_regions_3)):\n",
    "        new_regions_3[i] = new_regions[aa[i]]\n",
    "\n",
    "    for i in range(len(new_regions_3)):\n",
    "        for j in range(len(new_regions_3)):\n",
    "            max_1 = max( new_regions_3[i][1] , new_regions_3[j][1] )\n",
    "            min_1 = min( new_regions_3[i][3] + new_regions_3[i][1] , new_regions_3[j][3] + new_regions_3[j][1] )\n",
    "            if min_1-max_1 > ((new_regions_3[i][3]) + (new_regions_3[j][3]))/4.0:\n",
    "                line_idx[i,j] = 1\n",
    "\n",
    "    new_regions_update = []    \n",
    "\n",
    "    indexer = np.zeros(len(new_regions_3))\n",
    "    for i in range(len(new_regions_3)):\n",
    "        count = 0\n",
    "        for j in range(len(new_regions_3)):\n",
    "            if line_idx[j,i]==1:\n",
    "                indexer[i] = indexer[i] + new_regions_3[j][1]\n",
    "                count = count + 1\n",
    "        indexer[i] = indexer[i]/float(count)\n",
    "\n",
    "    kko =  []\n",
    "    kko.append(0)\n",
    "    count = 0\n",
    "    checker = np.zeros(len(new_regions_3))\n",
    "    for i in range(len(new_regions_3)):\n",
    "        for j in range(len(new_regions_3)):\n",
    "            if checker[j]==0 and line_idx[i,j]==1:\n",
    "                new_regions_update.append(new_regions_3[j])\n",
    "                checker[j] = 1\n",
    "                count  = count + 1\n",
    "        kko.append(count)\n",
    "\n",
    "    for i in range(len(kko)-1):\n",
    "        if kko[i+1]-kko[i]!=1 and kko[i+1]-kko[i]!=0:\n",
    "            part = np.asarray(new_regions_update[kko[i]:kko[i+1]])\n",
    "            part = part[np.argsort(part[:, 0])]\n",
    "            new_regions_update[kko[i]:kko[i+1]] = part\n",
    "        elif kko[i+1]-kko[i]==1:\n",
    "            part = np.asarray(new_regions_update[kko[i]:kko[i+1]])\n",
    "            new_regions_update[kko[i]:kko[i+1]] = part\n",
    "\n",
    "    for i in range(len(regions1)):\n",
    "        x,y,w,h = new_regions_update[i]\n",
    "        x = int(x)\n",
    "        y = int(y)\n",
    "        w = int(w)\n",
    "        h = int(h)\n",
    "        (positions1,Text_regions1) = charSegmentation.complete(deepcopy(gray_scale[y:y+h,x:x+w]))\n",
    "        for j in range(len(positions1)):\n",
    "            positions1[j][0] = np.clip(positions1[j][0],0,np.inf) + y\n",
    "            positions1[j][1] = np.clip(positions1[j][1],0,np.inf) + x\n",
    "            positions1[j][2] = np.clip(positions1[j][2],0,np.inf) + y\n",
    "            positions1[j][3] = np.clip(positions1[j][3],0,np.inf) + x\n",
    "            x1,y1,x2,y2 = positions1[j]\n",
    "            positions.append(positions1[j])\n",
    "            Text_regions.append(Text_regions1[j])\n",
    "            if j!=len(positions1)-1:\n",
    "                k.append(0)\n",
    "        \n",
    "        if not (len(positions1)<1):\n",
    "            k.append(1)\n",
    "\n",
    "    positions = (positions)\n",
    "    Text_regions = (Text_regions)\n",
    "\n",
    "    order = sorted(range(len(positions)),key=lambda k :positions[k])\n",
    "    line_idx = np.zeros((len(positions),len(positions)))\n",
    "\n",
    "    for i in range(len(positions)):\n",
    "        for j in range(len(positions)):\n",
    "            max_1 = max( positions[i][0] , positions[j][0] )\n",
    "            min_1 = min( positions[i][2] , positions[j][2] )\n",
    "\n",
    "            if min_1-max_1 > ((positions[i][2]-positions[i][0]) + (positions[j][2]-positions[j][0]))/5.0:\n",
    "                line_idx[i,j] = 1\n",
    "\n",
    "\n",
    "    corresponding_cluster = np.zeros(len(positions))\n",
    "\n",
    "    for i in range(len(positions)-1):\n",
    "        if not(line_idx[i,i+1]==1 and line_idx[i+1,i]==1):\n",
    "            corresponding_cluster[i+1] = 1\n",
    "\n",
    "    chars = []\n",
    "    vattu_gunintam = []\n",
    "    output = []\n",
    "\n",
    "    for i in range(len(Text_regions)):\n",
    "        # segmentation of character\n",
    "        img = utils.crop(Text_regions[i])\n",
    "        cv2.imwrite('output/segmentedChars/'+str(i)+'.PNG',img)\n",
    "        img = Image.open('output/segmentedChars/'+str(i)+'.PNG')\n",
    "        img.load()\n",
    "        if img.size!=(32,32):\n",
    "            img = img.resize((32,32),Image.ANTIALIAS)\n",
    "        img = np.asarray(img).reshape(1,1,32,32)\n",
    "        img = img.astype('float32')\n",
    "        img = img/255.0\n",
    "\n",
    "        # Prediction of char\n",
    "        out =  model_1.predict(img)\n",
    "        output = [output,np.where(out==out.max())[1][:]+1]\n",
    "        chars.append(np.where(out==out.max())[1][:]+1)\n",
    "\n",
    "        # Prediction of vattu or gunintam if necessary\n",
    "        if np.where(out==out.max())[1][:]+1>=20 and np.where(out==out.max())[1][:]+1<=55:\n",
    "            out2 = model_2.predict(img)\n",
    "            vattu_gunintam.append(np.where(out2==out2.max())[1][:]+1)\n",
    "        else:\n",
    "            vattu_gunintam.append(-1)\n",
    "\n",
    "    file = open('output/result.html','w')\n",
    "    \n",
    "    # writing output in html format \n",
    "\n",
    "    for i in range(len(chars)):\n",
    "        if i>0:\n",
    "            if corresponding_cluster[i] == 1:\n",
    "                file.write('<br/>')\n",
    "            elif k[i-1]==1 :\n",
    "                file.write('&#32;')\n",
    "        file.write((char_2[int(chars[i])-1][:-1]))\n",
    "        if vattu_gunintam[i]!=-1 and vattu_gunintam[i] !=1:\n",
    "            file.write(vattu_2[int(vattu_gunintam[i])-1][:-1])\n",
    "\n",
    "    file.close()\n",
    "    \n",
    "    # processing of speech\n",
    "    #os.system(\"espeak -m -v te -s 100 -f output/result.html -w output/speech.wav\")\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
